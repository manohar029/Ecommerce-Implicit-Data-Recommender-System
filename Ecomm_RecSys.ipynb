{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Ecomm RecSys.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manohar029/Ecommerce-Implicit-Data-Recommender-System/blob/master/Ecomm_RecSys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-tkfq9OmgFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install the necessary packages in your colab session\n",
        "!pip install implicit\n",
        "!pip install ml_metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw6dw4znXtpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "import os\n",
        "import implicit\n",
        "import scipy.sparse as sparse\n",
        "import ml_metrics as metrics\n",
        "from google.colab import files\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9dBAylnm4eI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdAgXo7q4osc",
        "colab_type": "text"
      },
      "source": [
        "### Load and Pre-process the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LmCEFHJmgFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clicks_df = pd.read_csv('/content/gdrive/My Drive/Ecomm_RecSys/yoochoose-clicks.dat', \n",
        "                 sep=\",\", \n",
        "                 skiprows=1,  \n",
        "                 names=['sessionID','timestamp','itemID','category'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXv7c5ChmgFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "buys_df = pd.read_csv('/content/gdrive/My Drive/Ecomm_RecSys/yoochoose-buys.dat', \n",
        "                 sep=\",\", \n",
        "                 skiprows=1,  \n",
        "                 names=['sessionID','timestamp','itemID','price','quantity'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udy_Tt1zmgFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(clicks_df.shape)\n",
        "clicks_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dCVrkewLnFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(buys_df.shape)\n",
        "buys_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQjxHn11mgFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clicks_df['category'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwW3op79ZLax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## we'll select a category with maximum clicks to build our recommendation system on. \n",
        "## intuitively, it doesn't make sense to recommend items of one category if the user is searching for an item in some other category.\n",
        "## Ex. you don't get recommendations of tshirts if you are searching for wallets in the 'accessories' category.\n",
        "\n",
        "clicks_df = clicks_df[clicks_df['category']==0]\n",
        "clicks_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqJz6azybcbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## since we are selecting a single category, we only want the buys information from those sessions. \n",
        "\n",
        "buys_df = buys_df.loc[buys_df['sessionID'].isin(clicks_df.sessionID.unique())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UThCvDwmmgFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "buys_df.drop(columns=['price','quantity'], inplace = True)\n",
        "clicks_df.drop(columns=['category'], inplace = True)\n",
        "clicks_df['timestamp'] = pd.to_datetime(clicks_df['timestamp'])\n",
        "buys_df['timestamp'] = pd.to_datetime(buys_df['timestamp'])\n",
        "buys_df['buys'] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POZAA9BdmgF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_df = pd.concat([clicks_df,buys_df], axis=0, ignore_index=True)\n",
        "all_df['itemID'].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA_d1bU_yO-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(clicks_df)\n",
        "del(buys_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esxijx9OmgGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## NOTE: This is just for implementation purpose.\n",
        "\n",
        "## Since we don't have any information of the users, we are considering a total of 0.5M users, and randomly assigning users to each row of all_df. \n",
        "## This gives uniform distribution of clicks and buys accross all the users which definitely may not be the same as what prevails in the industry. \n",
        "## Also, by doing this we might get some users buying an item without any clicks. \n",
        "## Anyway, we would not encounter this situation in practical scenarios as the userID will also be tracked and stored along with the clicks. \n",
        "\n",
        "userIDs = randint(1,500000,all_df.shape[0])\n",
        "\n",
        "all_df['userID'] = userIDs\n",
        "all_df.sort_values(by='timestamp', inplace=True)\n",
        "print(all_df.shape)\n",
        "all_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OCzXp5HsarW-",
        "colab": {}
      },
      "source": [
        "## we also need to look for the distribution of clicks accross months since we'll take a time based split to form the test set. \n",
        "\n",
        "all_df['month'] = all_df['timestamp'].dt.month \n",
        "print(all_df.shape)\n",
        "print(all_df['month'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAczoL49mgHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Here we are making a time based split of the data. Later, the test_df will be preprocessed further to match the requirements of our approach.\n",
        "## We are taking the last 2.5M rows into our test set. \n",
        "train_df = all_df[:-2500000]\n",
        "test_df = all_df[-2500000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oco8lAjmgHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(all_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaJXDFtNmgHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_df.shape)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "471tfTKamgHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['buys'].fillna(0, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w_Gx53UmgH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_clicks = train_df.loc[train_df['buys'] == 0]\n",
        "train_buys = train_df.loc[train_df['buys'] == 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M62k5XwHmgH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLA_87lHmgH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_clicks = train_clicks.groupby(['userID','itemID'])['buys'].count().reset_index().rename(columns = {'buys':'clicks'})\n",
        "train_buys = train_buys.groupby(['userID','itemID'])['buys'].count().reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT2G1YutmgIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_clicks.shape)\n",
        "print(train_buys.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZhA64oQmgIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_final = pd.merge(train_clicks,train_buys, how='outer', on=['userID','itemID'])\n",
        "print(train_final.shape)\n",
        "train_final.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUDJaMHlmgIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(train_clicks)\n",
        "del(train_buys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCxa2QsLmgIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_final.fillna(0, inplace= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKwrVWMzmgIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## we'll combine the implicit user activity data by weighting to form a rating. \n",
        "## If more implicit variables are available like page_views, clicks, add_to_carts, transactions etc., all of them can be combined likewise and the \n",
        "## weights can be decided by cross validation. \n",
        "\n",
        "train_final['rating'] = 0.25*train_final['clicks'] + 1*train_final['buys']\n",
        "train_final.drop(columns=['clicks','buys'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q9IQwv_k5kB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_final['userID'] = train_final['userID'].astype(\"category\")\n",
        "train_final['itemID'] = train_final['itemID'].astype(\"category\")\n",
        "train_final['userID_enc'] = train_final['userID'].cat.codes\n",
        "train_final['itemID_enc'] = train_final['itemID'].cat.codes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfG3vuIKoYmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## we create the mappings for the userIDs and itemIDs with their encodings. This would be useful during the time of testing.\n",
        "\n",
        "cat_item_map = dict(enumerate(train_final['itemID'].cat.categories))\n",
        "item_cat_map = dict((v,k) for k,v in cat_item_map.items())\n",
        "cat_user_map = dict(enumerate(train_final['userID'].cat.categories))\n",
        "user_cat_map = dict((v,k) for k,v in cat_user_map.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBkKuDyX4cpg",
        "colab_type": "text"
      },
      "source": [
        "### Training the Implicit ALS model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51-ZB_q0mgIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Implicit ALS model requires item-user sparsematrix as input, so below we are building the same. \n",
        "sparse_item_user = sparse.csr_matrix((train_final['rating'].astype(float), (train_final['itemID_enc'], train_final['userID_enc'])))\n",
        "sparse_user_item = sparse.csr_matrix((train_final['rating'].astype(float), (train_final['userID_enc'], train_final['itemID_enc'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxuLgYoY1TaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(train_final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoawuQrbmgIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = implicit.als.AlternatingLeastSquares(factors=20, regularization=0.1, iterations=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAbxmHehVY6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "# If you get any warning regarding 'OPENBLAS_NUM_THREADS' or 'MKL_NUM_THREADS' run the below commands and re-run the above cell.\n",
        "os.environ['OPENBLAS_NUM_THREADS'] = \"1\"\n",
        "os.environ['MKL_NUM_THREADS'] = \"1\"\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LjaxRqrmgIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha_val = 15\n",
        "sparse_item_user = (sparse_item_user * alpha_val).astype('double')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSpl1rHYmgIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(sparse_item_user, show_progress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUMPr3lG4GiZ",
        "colab_type": "text"
      },
      "source": [
        "### Pre-processing the test_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0frEAQggQT8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## we want only the users and items in the test data which are already present in the training data.\n",
        "## NOTE that this method can't be used for a cold start problem.\n",
        "\n",
        "print(train_final['itemID'].nunique())\n",
        "print(test_df['itemID'].nunique())\n",
        "print(len(set(test_df.itemID).intersection(set(train_final.itemID))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64rUCq2U9Db7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Since we want to generate the recommendations with respect to the query of the user, our approach to create the test set is that the first occurence\n",
        "## of a user and the item corresponding to that user's first occurence is considered as the query of that user. All the remaining items of that user's\n",
        "## occurences are taken as  the ground truth items which we'll try to recommend using our recommender system. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiiZyiDUUmge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = test_df.loc[test_df['itemID'].isin(list(set(test_df.itemID).intersection(set(train_final.itemID))))]\n",
        "test_user_item_df = test_df.drop_duplicates('userID', keep='first').drop(columns=['buys','sessionID'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMei-PBfWgIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_df = pd.concat([test_df[['itemID','timestamp','userID']],test_user_item_df], axis=0).drop_duplicates(keep=False).drop(\n",
        "    columns=['timestamp']).reset_index(drop=True)\n",
        "temp_df = temp_df.groupby('userID')['itemID'].apply(list).reset_index().rename(columns={'itemID':'itemID_list'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaoKxQlvdlQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_df = test_user_item_df.merge(temp_df, how='inner', on='userID').drop(columns=['timestamp'])\n",
        "print(valid_df.shape)\n",
        "valid_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09b3ZdYlgHMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## As a baseline, we can generate the recommendations by considering only the top n items corresponding to the query item. \n",
        "## Since it is item based similarity, we cannot capture the user behaviour/preferences into this i.e recommendation is not personalized.\n",
        "\n",
        "n_similar = 6\n",
        "item_recs = []\n",
        "\n",
        "for item_id in valid_df['itemID'].values:\n",
        "\n",
        "  similar = model.similar_items(item_cat_map[item_id], n_similar)\n",
        "  similar = similar[1:]\n",
        "  items_cat = [x[0] for x in similar]\n",
        "  items = [cat_item_map[x] for x in items_cat]\n",
        "  item_recs.append(items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFaF_JRU14CW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Here, since we take the dot product of the user's latent vector with that of the item latent vectors, we'll be able to personalize the recommendations\n",
        "## to the user.\n",
        "\n",
        "n_rec = 5\n",
        "user_recs = []\n",
        "\n",
        "for user_id in valid_df['userID'].values:\n",
        "  \n",
        "  recommended = model.recommend(user_cat_map[user_id], sparse_user_item, n_rec)\n",
        "  items_cat = [x[0] for x in recommended]\n",
        "  items = [cat_item_map[x] for x in items_cat]\n",
        "  user_recs.append(items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_ZBv8wdBzdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## The above method is good for personalized recommendations, but, since we also want to consider the context of the query, we would be assuming that \n",
        "## all the products are equally similar to the query product, which would seldom be true. \n",
        "## Hence, we are taking the weighted average of both item based similarity scores and the user-item similarity scores. \n",
        "\n",
        "item_vecs = model.item_factors\n",
        "user_vecs = model.user_factors\n",
        "item_norms = np.sqrt((item_vecs * item_vecs).sum(axis=1))\n",
        "ensemble_recs = []\n",
        "n_rec=3\n",
        "\n",
        "for item_id,user_id in zip(valid_df['itemID'],valid_df['userID']):\n",
        "  item_scores = item_vecs.dot(item_vecs[item_cat_map[item_id]])/item_norms\n",
        "  \n",
        "  user_interactions = sparse_user_item[user_cat_map[user_id],:].toarray()\n",
        "  user_interactions = user_interactions.reshape(-1) + 1\n",
        "  user_interactions[user_interactions >1] = 0\n",
        "  rec_vector = user_vecs[user_cat_map[user_id],:].dot(item_vecs.T)\n",
        "  user_scores = user_interactions*rec_vector\n",
        "\n",
        "  ensemble_scores = 0.5*item_scores + 0.5*user_scores\n",
        "  best = np.argpartition(ensemble_scores, -3)[-3:]\n",
        "  top_items = sorted(zip(best, ensemble_scores[best]), key=lambda x: -x[1])\n",
        "\n",
        "  top_items_cat = [x[0] for x in top_items]\n",
        "  top_items = [cat_item_map[x] for x in top_items_cat]\n",
        "  ensemble_recs.append(top_items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FFTh1fnko7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actuals = list(valid_df['itemID_list'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toXpu4-_liZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics.mapk(actuals,item_recs,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRsjQlhllu8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics.mapk(actuals,user_recs,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvMA7DgOZwD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics.mapk(actuals,ensemble_recs,3)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}